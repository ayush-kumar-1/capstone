{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f358f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Ayush\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys; sys.path.insert(0, '../') #adds all the code we've written in src\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dbdc6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>Black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>Turner did not withhold his disappointment. Tu...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>I swear to God. This dumb nigger bitch. I have...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>Yea fuck you RT @therealexel: IF YOURE A NIGGE...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...</td>\n",
       "      <td>ethnicity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47692 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text cyberbullying_type\n",
       "0      In other words #katandandre, your food was cra...  not_cyberbullying\n",
       "1      Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying\n",
       "2      @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying\n",
       "3      @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying\n",
       "4      @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying\n",
       "...                                                  ...                ...\n",
       "47687  Black ppl aren't expected to do anything, depe...          ethnicity\n",
       "47688  Turner did not withhold his disappointment. Tu...          ethnicity\n",
       "47689  I swear to God. This dumb nigger bitch. I have...          ethnicity\n",
       "47690  Yea fuck you RT @therealexel: IF YOURE A NIGGE...          ethnicity\n",
       "47691  Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...          ethnicity\n",
       "\n",
       "[47692 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../cyberbullying_tweets/cyberbullying_tweets.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e119ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "%time df[\"processed_text\"] = preprocess_all(df.tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cee11d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "574bfb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In other words #katandandre, your food was cra...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[word, katandandre, food, crapilicious]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why is #aussietv so white? #MKR #theblock #ImA...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[aussietv, white, theblock, imacelebrityau, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@XochitlSuckkks a classy whore? Or more red ve...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[xochitlsuckkks, classy, whore, red, velvet, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Jason_Gio meh. :P  thanks for the heads up, b...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[jason_gio, meh, p, thanks, head, concerned, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@RudhoeEnglish This is an ISIS account pretend...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[rudhoeenglish, isi, account, pretending, kurd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>Black ppl aren't expected to do anything, depe...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[black, ppl, expected, anything, depended, any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>Turner did not withhold his disappointment. Tu...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[turner, withhold, disappointment, turner, cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>I swear to God. This dumb nigger bitch. I have...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[swear, god, dumb, nigger, bitch, got, bleach,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>Yea fuck you RT @therealexel: IF YOURE A NIGGE...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[yea, fuck, therealexel, nigger, fucking, unfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[bro, got, chill, chillshrammy, dog, fuck, kp,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47692 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text cyberbullying_type  \\\n",
       "0      In other words #katandandre, your food was cra...  not_cyberbullying   \n",
       "1      Why is #aussietv so white? #MKR #theblock #ImA...  not_cyberbullying   \n",
       "2      @XochitlSuckkks a classy whore? Or more red ve...  not_cyberbullying   \n",
       "3      @Jason_Gio meh. :P  thanks for the heads up, b...  not_cyberbullying   \n",
       "4      @RudhoeEnglish This is an ISIS account pretend...  not_cyberbullying   \n",
       "...                                                  ...                ...   \n",
       "47687  Black ppl aren't expected to do anything, depe...          ethnicity   \n",
       "47688  Turner did not withhold his disappointment. Tu...          ethnicity   \n",
       "47689  I swear to God. This dumb nigger bitch. I have...          ethnicity   \n",
       "47690  Yea fuck you RT @therealexel: IF YOURE A NIGGE...          ethnicity   \n",
       "47691  Bro. U gotta chill RT @CHILLShrammy: Dog FUCK ...          ethnicity   \n",
       "\n",
       "                                          processed_text  \n",
       "0                [word, katandandre, food, crapilicious]  \n",
       "1      [aussietv, white, theblock, imacelebrityau, to...  \n",
       "2      [xochitlsuckkks, classy, whore, red, velvet, c...  \n",
       "3      [jason_gio, meh, p, thanks, head, concerned, a...  \n",
       "4      [rudhoeenglish, isi, account, pretending, kurd...  \n",
       "...                                                  ...  \n",
       "47687  [black, ppl, expected, anything, depended, any...  \n",
       "47688  [turner, withhold, disappointment, turner, cal...  \n",
       "47689  [swear, god, dumb, nigger, bitch, got, bleach,...  \n",
       "47690  [yea, fuck, therealexel, nigger, fucking, unfo...  \n",
       "47691  [bro, got, chill, chillshrammy, dog, fuck, kp,...  \n",
       "\n",
       "[47692 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbca0545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_bow(text_arr, num_grams = 1): \n",
    "    \"\"\"\n",
    "    Returns the bag of words array for an array of preprocessed text. \n",
    "    \n",
    "    params:\n",
    "    -----------------------\n",
    "    text_arr: pd.Series object of strings \n",
    "    \n",
    "    return: \n",
    "    ----------------------\n",
    "    numpy sparse matrix of of size n times m where n is the number \n",
    "    of text samples, and m is the number of words/n-grams in the corpus \n",
    "    \"\"\"\n",
    "    vectorizer = CountVectorizer(stop_words='english', ngram_range=(num_grams,num_grams))\n",
    "    return vectorizer.fit_transform(text_arr)\n",
    "\n",
    "X_unigrams = get_bow(df.processed_text.apply(lambda row: \"\\s\".join(row)))\n",
    "X_bigrams = get_bow(df.processed_text.apply(lambda row: \"\\s\".join(row)), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "20dd99ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ayush\\.conda\\envs\\nlp\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__</th>\n",
       "      <th>_____</th>\n",
       "      <th>___arie</th>\n",
       "      <th>___mntana</th>\n",
       "      <th>__alexithymia</th>\n",
       "      <th>__brighterdays</th>\n",
       "      <th>__citgo</th>\n",
       "      <th>__deesire__</th>\n",
       "      <th>__eaeolian</th>\n",
       "      <th>__enimey__</th>\n",
       "      <th>...</th>\n",
       "      <th>ラストのパンツ</th>\n",
       "      <th>ラスパンじっくり見よ</th>\n",
       "      <th>レオン</th>\n",
       "      <th>ワーオｗｗｗ</th>\n",
       "      <th>死なばもろとも</th>\n",
       "      <th>自動post</th>\n",
       "      <th>自殺</th>\n",
       "      <th>自殺するのは憎い相手を殺した後</th>\n",
       "      <th>𝕧𝕖𝕣𝕠𝕟𝕚𝕔𝕒</th>\n",
       "      <th>𝚎𝚕𝚞𝚜𝚒𝚟𝚎</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47687</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47689</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47690</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47691</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47692 rows × 66667 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       __  _____  ___arie  ___mntana  __alexithymia  __brighterdays  __citgo  \\\n",
       "0       0      0        0          0              0               0        0   \n",
       "1       0      0        0          0              0               0        0   \n",
       "2       0      0        0          0              0               0        0   \n",
       "3       0      0        0          0              0               0        0   \n",
       "4       0      0        0          0              0               0        0   \n",
       "...    ..    ...      ...        ...            ...             ...      ...   \n",
       "47687   0      0        0          0              0               0        0   \n",
       "47688   0      0        0          0              0               0        0   \n",
       "47689   0      0        0          0              0               0        0   \n",
       "47690   0      0        0          0              0               0        0   \n",
       "47691   0      0        0          0              0               0        0   \n",
       "\n",
       "       __deesire__  __eaeolian  __enimey__  ...  ラストのパンツ  ラスパンじっくり見よ  レオン  \\\n",
       "0                0           0           0  ...        0           0    0   \n",
       "1                0           0           0  ...        0           0    0   \n",
       "2                0           0           0  ...        0           0    0   \n",
       "3                0           0           0  ...        0           0    0   \n",
       "4                0           0           0  ...        0           0    0   \n",
       "...            ...         ...         ...  ...      ...         ...  ...   \n",
       "47687            0           0           0  ...        0           0    0   \n",
       "47688            0           0           0  ...        0           0    0   \n",
       "47689            0           0           0  ...        0           0    0   \n",
       "47690            0           0           0  ...        0           0    0   \n",
       "47691            0           0           0  ...        0           0    0   \n",
       "\n",
       "       ワーオｗｗｗ  死なばもろとも  自動post  自殺  自殺するのは憎い相手を殺した後  𝕧𝕖𝕣𝕠𝕟𝕚𝕔𝕒  𝚎𝚕𝚞𝚜𝚒𝚟𝚎  \n",
       "0           0        0       0   0                0         0        0  \n",
       "1           0        0       0   0                0         0        0  \n",
       "2           0        0       0   0                0         0        0  \n",
       "3           0        0       0   0                0         0        0  \n",
       "4           0        0       0   0                0         0        0  \n",
       "...       ...      ...     ...  ..              ...       ...      ...  \n",
       "47687       0        0       0   0                0         0        0  \n",
       "47688       0        0       0   0                0         0        0  \n",
       "47689       0        0       0   0                0         0        0  \n",
       "47690       0        0       0   0                0         0        0  \n",
       "47691       0        0       0   0                0         0        0  \n",
       "\n",
       "[47692 rows x 66667 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bow_sklearn = pd.DataFrame(X_unigrams.toarray(),columns=vectorizer.get_feature_names())\n",
    "df_bow_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04cb7f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cyberbullying_type</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RT @Kurdsnews: Turkish state has killed 241 ch...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[kurdsnews, turkish, state, killed, child, las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Kids Love😘❤ @ Mohamad Bin Zayed City مدينة محم...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[kid, love😘❤, mohamad, bin, zayed, city, مدينة...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>@sand_dejesus Isso é bullying! @O_Patriarca</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[sand_dejesus, isso, é, bullying, o_patriarca]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>@janaane poise, odiei aquilo ele sofria bullyi...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[janaane, poise, odiei, aquilo, ele, sofria, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>RT @Hanar_Marouf: Daesh is distrbuting Stolen ...</td>\n",
       "      <td>not_cyberbullying</td>\n",
       "      <td>[hanar_marouf, daesh, distrbuting, stolen, you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47675</th>\n",
       "      <td>Y'all make sure y'all following a nigga #coon⛽...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[make, sure, following, nigga, coon⛽🅰🆖💯lilbitc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47679</th>\n",
       "      <td>i’ve noticed it’s a trend on here y’all have t...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[noticed, trend, belittle, accomplishment, mak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47681</th>\n",
       "      <td>As a black man I’m not supporting music that t...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[black, man, supporting, music, tell, go, kill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47682</th>\n",
       "      <td>But... he’s right. Atlanta is full of so calle...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[right, atlanta, full, called, shoot, negro, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47688</th>\n",
       "      <td>Turner did not withhold his disappointment. Tu...</td>\n",
       "      <td>ethnicity</td>\n",
       "      <td>[turner, withhold, disappointment, turner, cal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9154 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweet_text cyberbullying_type  \\\n",
       "13     RT @Kurdsnews: Turkish state has killed 241 ch...  not_cyberbullying   \n",
       "21     Kids Love😘❤ @ Mohamad Bin Zayed City مدينة محم...  not_cyberbullying   \n",
       "26           @sand_dejesus Isso é bullying! @O_Patriarca  not_cyberbullying   \n",
       "48     @janaane poise, odiei aquilo ele sofria bullyi...  not_cyberbullying   \n",
       "67     RT @Hanar_Marouf: Daesh is distrbuting Stolen ...  not_cyberbullying   \n",
       "...                                                  ...                ...   \n",
       "47675  Y'all make sure y'all following a nigga #coon⛽...          ethnicity   \n",
       "47679  i’ve noticed it’s a trend on here y’all have t...          ethnicity   \n",
       "47681  As a black man I’m not supporting music that t...          ethnicity   \n",
       "47682  But... he’s right. Atlanta is full of so calle...          ethnicity   \n",
       "47688  Turner did not withhold his disappointment. Tu...          ethnicity   \n",
       "\n",
       "                                          processed_text  \n",
       "13     [kurdsnews, turkish, state, killed, child, las...  \n",
       "21     [kid, love😘❤, mohamad, bin, zayed, city, مدينة...  \n",
       "26        [sand_dejesus, isso, é, bullying, o_patriarca]  \n",
       "48     [janaane, poise, odiei, aquilo, ele, sofria, b...  \n",
       "67     [hanar_marouf, daesh, distrbuting, stolen, you...  \n",
       "...                                                  ...  \n",
       "47675  [make, sure, following, nigga, coon⛽🅰🆖💯lilbitc...  \n",
       "47679  [noticed, trend, belittle, accomplishment, mak...  \n",
       "47681  [black, man, supporting, music, tell, go, kill...  \n",
       "47682  [right, atlanta, full, called, shoot, negro, w...  \n",
       "47688  [turner, withhold, disappointment, turner, cal...  \n",
       "\n",
       "[9154 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def isEnglish(s):\n",
    "    try:\n",
    "        s.encode(encoding='utf-8').decode('ascii')\n",
    "    except UnicodeDecodeError:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "df[~tweets.apply(lambda row: isEnglish(row))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c4e79d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets[~tweets.apply(isEnglish)].to_csv(\"non-english.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b4664b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "tweets = df.processed_text.apply(lambda row: \" \".join(row)).apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9d7031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_dict = {}\n",
    "for i, type in enumerate(df.cyberbullying_type.unique()):\n",
    "    cat_dict[type] = i \n",
    "    \n",
    "df[\"Y\"] = df.cyberbullying_type.map(cat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3f98bf9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "47687    5\n",
       "47688    5\n",
       "47689    5\n",
       "47690    5\n",
       "47691    5\n",
       "Name: Y, Length: 47692, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "71e790e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df.Y, test_size=0.2, random_state=42)\n",
    "\n",
    "log_reg = LR(max_iter=10000, solver = 'saga').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2733a930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.37      0.34      1369\n",
      "           1       0.65      0.92      0.76      1076\n",
      "           2       0.71      0.95      0.81      1162\n",
      "           3       0.70      0.35      0.47      3201\n",
      "           4       0.86      0.98      0.92      1408\n",
      "           5       0.81      0.98      0.88      1323\n",
      "\n",
      "    accuracy                           0.67      9539\n",
      "   macro avg       0.67      0.76      0.70      9539\n",
      "weighted avg       0.68      0.67      0.65      9539\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report \n",
    "y_pred = log_reg.predict(X_test)\n",
    "print(classification_report(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2e29c20a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../category_dict.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_85268/1730777121.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../category_dict.json\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcat_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../category_dict.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open(\"../category_dict.json\") as file:\n",
    "    json.dump(cat_dict, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
